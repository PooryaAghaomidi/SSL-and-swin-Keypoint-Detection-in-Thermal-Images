{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595af3ab",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d73195a-1ac0-40e9-b1aa-0376469ff50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03531806",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Hardware and framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_details = pd.DataFrame({\n",
    "    'Title':       ['GPU', 'CPU', 'RAM', 'Windows', 'Python', 'Tensorflow'],\n",
    "    'Information': ['NVIDIA GeForce RTX 2080Ti', 'AMD Ryzen 9 3950X 16-Core Processor',\n",
    "                    '128 GB', 'Windows 10 Enterprise', '3.7', '2.4']\n",
    "    })\n",
    "system_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e32561-9006-4156-979a-3c830c4dae95",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Pretexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11714ca4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pretext model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1047f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretext_parameters = pd.DataFrame({\n",
    "    'Task':      ['Gender, rotation, and subject', 'Inpainting',\n",
    "                  'Gender, rotation, and subject', 'Inpainting', 'all', 'all', 'all',\n",
    "                  'all'],\n",
    "    'Parameter': ['Loss', 'Loss', 'Metric', 'Metric', 'Learning rate', 'Optimizer',\n",
    "                  'Batch size', 'Epoch'],\n",
    "    'Value':     ['categorical cross entropy', 'mse', 'Accuracy', 'PSNR',\n",
    "                  '0.01 (Reduce LR On Plateau to 0.000001)', 'RMSprop', '16', '300']\n",
    "    })\n",
    "pretext_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4198c73-2b2f-49c4-b541-cb1f7a1f454e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Inpainting - image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc923c-304e-4d79-a9e4-d9fe235b9832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(super_resolution, high_resolution):\n",
    "    psnr_value = tf.image.psnr(high_resolution, super_resolution, max_val = 1)[0]\n",
    "    return psnr_value\n",
    "\n",
    "\n",
    "def SSIMLoss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "\n",
    "model = load_model('checkpoint_loss2', custom_objects = {'PSNR': PSNR, 'SSIMLoss': SSIMLoss})\n",
    "folder = 'F:/poorya/datasets/keypoint J dataset/pretext dataset/test/'\n",
    "i = 50\n",
    "n = os.listdir(folder)\n",
    "n.sort(key = len)\n",
    "\n",
    "images = []\n",
    "mask = []\n",
    "rotation = []\n",
    "gender = []\n",
    "subject = []\n",
    "\n",
    "train_img_1 = image.img_to_array(image.load_img(folder + n[i], color_mode = \"grayscale\", target_size = (384, 384)))\n",
    "train_img_2 = image.img_to_array(image.load_img(folder + n[i], color_mode = \"grayscale\", target_size = (384, 384)))\n",
    "train_img_1 /= 255.0\n",
    "train_img_2 /= 255.0\n",
    "\n",
    "mask.append(train_img_1[168:216, 168:216])\n",
    "train_img_2[168:216, 168:216] = (0)\n",
    "images.append(train_img_2)\n",
    "\n",
    "rotation.append(to_categorical(int(n[i][-10]), num_classes = 4))\n",
    "subject.append(to_categorical(int(n[i][-6:-4]) - 1, num_classes = 89))\n",
    "gender.append(to_categorical(int(n[i][-8]), num_classes = 2))\n",
    "y1_pred, y2_pred, y3_pred, y4_pred = model.predict(np.array(images))\n",
    "\n",
    "plt.imshow(np.array(mask)[0, :, :, :])\n",
    "plt.show()\n",
    "plt.imshow(y4_pred[0, :, :, :])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(train_img_1)\n",
    "plt.show()\n",
    "\n",
    "train_img_2[168:216, 168:216] = y4_pred[0, :, :, :]\n",
    "plt.imshow(train_img_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f2781",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pretexts results - table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8c538-6c21-4123-a7e9-1446559bf044",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = []\n",
    "my_subjects = {}\n",
    "counter = 0\n",
    "\n",
    "files = os.listdir('F:/poorya/datasets/keypoint J dataset/pretext dataset/train_aug/')\n",
    "\n",
    "for i in files:\n",
    "    sub.append(i[-6:-4])\n",
    "\n",
    "for i in range(95):\n",
    "    if str(i).zfill(2) in sub:\n",
    "        my_subjects[str(i).zfill(2)] = counter\n",
    "        counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb03c0-4830-4dff-9034-aeb2a010306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, folder, batch_size, my_subjects):\n",
    "        self.folder = folder\n",
    "        self.n = os.listdir(folder)\n",
    "        self.batch_size = batch_size\n",
    "        self.my_subjects = my_subjects\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.n) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        list_IDs_temp = [self.n[k] for k in indexes]\n",
    "        x, y = self.__data_generation(list_IDs_temp)\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.n))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        images = np.empty((self.batch_size, 384, 384, 1))\n",
    "        masks = np.empty((self.batch_size, 48, 48, 1))\n",
    "        rotation = np.empty((self.batch_size), dtype = int)\n",
    "        subject = np.empty((self.batch_size), dtype = int)\n",
    "        gender = np.empty((self.batch_size), dtype = int)\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "\n",
    "            train_img_1 = image.img_to_array(image.load_img(self.folder + ID, color_mode = \"grayscale\", target_size = (\n",
    "                384, 384)))\n",
    "            train_img_1 /= 255.0\n",
    "            masks[i,] = train_img_1[168:216, 168:216]\n",
    "\n",
    "            train_img_2 = image.img_to_array(image.load_img(self.folder + ID, color_mode = \"grayscale\", target_size = (\n",
    "                384, 384)))\n",
    "            train_img_2 /= 255.0\n",
    "            train_img_2[168:216, 168:216] = 0\n",
    "            images[i,] = train_img_2\n",
    "\n",
    "            rotation[i] = int(ID[-10])\n",
    "            subject[i] = int(self.my_subjects[ID[-6:-4]])\n",
    "            gender[i] = int(ID[-8])\n",
    "\n",
    "        return images, [to_categorical(gender, num_classes = 2), to_categorical(rotation, num_classes = 4),\n",
    "                        to_categorical(subject, num_classes = 89), masks]\n",
    "\n",
    "\n",
    "bs = 16\n",
    "test_gen = DataGenerator('F:/poorya/datasets/keypoint J dataset/pretext dataset/test/', bs, my_subjects)\n",
    "model.evaluate(test_gen, steps = len(os.listdir('F:/poorya/datasets/keypoint J dataset/pretext dataset/val/')) // bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretext_results = pd.DataFrame({\n",
    "    'Task':  ['Gender', 'Rotation', 'Subject', 'Inpainting'],\n",
    "    'Value': ['Accuracy = 98.96', 'Accuracy = 99.31', 'Accuracy = 67.01', 'PSNR = 21.90']\n",
    "    })\n",
    "pretext_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb46615b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pretext confusion matrices - cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(folder):\n",
    "    n = os.listdir(folder)\n",
    "    n.sort(key = len)\n",
    "\n",
    "    images = []\n",
    "    rotation = []\n",
    "    subject = []\n",
    "    gender = []\n",
    "\n",
    "    for i in range(len(n)):\n",
    "        train_img_2 = image.img_to_array(image.load_img(folder + n[i], color_mode = \"grayscale\", target_size = (\n",
    "            384, 384)))\n",
    "        train_img_2 /= 255.0\n",
    "        train_img_2[168:216, 168:216] = 0\n",
    "        images.append(train_img_2)\n",
    "\n",
    "        rotation.append(to_categorical(int(n[i][-10]), num_classes = 4))\n",
    "        subject.append(to_categorical(int(my_subjects[n[i][-6:-4]]), num_classes = 89))\n",
    "        gender.append(to_categorical(int(n[i][-8]), num_classes = 2))\n",
    "\n",
    "    return np.array(images), [np.array(gender), np.array(rotation), np.array(subject)]\n",
    "\n",
    "\n",
    "x_test, y_true = image_generator('F:/poorya/datasets/keypoint J dataset/pretext dataset/test/')\n",
    "predictions = model.predict(x_test, batch_size = 1, verbose = 1, steps = len(os.listdir('F:/poorya/datasets/keypoint J dataset/pretext dataset/test/')) // 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62f1fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def change(x):\n",
    "    answer = np.zeros((np.shape(x)[0]))\n",
    "    for i in range(np.shape(x)[0]):\n",
    "        max_value = max(x[i, :])\n",
    "        max_index = list(x[i, :]).index(max_value)\n",
    "        answer[i] = max_index\n",
    "    return answer.astype(int)\n",
    "\n",
    "\n",
    "labels = [['Male', 'Female'],\n",
    "          ['0 degrees', '90 degrees', '180 degrees', '270 degrees'],\n",
    "          [str(k + 1) for k in range(89)]]\n",
    "\n",
    "cm = confusion_matrix(change(y_true[0]), change(predictions[0]))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = labels[0])\n",
    "disp.plot(cmap = plt.cm.Blues)\n",
    "plt.savefig('1.jpg')\n",
    "plt.show()\n",
    "\n",
    "cm = confusion_matrix(change(y_true[1]), change(predictions[1]))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = labels[1])\n",
    "disp.plot(cmap = plt.cm.Blues)\n",
    "plt.savefig('2.jpg')\n",
    "plt.show()\n",
    "\n",
    "sub_pred = np.append(change(predictions[2]), [73, 78])\n",
    "sub_true = np.append(change(y_true[2]), [73, 78])\n",
    "fig, ax = plt.subplots(figsize = (20, 20))\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "cm = confusion_matrix(sub_true, sub_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = labels[2])\n",
    "disp.plot(cmap = plt.cm.Blues, ax = ax)\n",
    "plt.savefig('3.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f5bd9a-729a-4470-a167-eaca00d80771",
   "metadata": {},
   "source": [
    "# Face detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ca34c4-5f4d-4226-8040-c24113dd8f51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Face detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36207e43-f9bd-492b-83e7-edf9ef7eb7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretext_parameters = pd.DataFrame({\n",
    "    'Parameter': ['Loss', 'Metric', 'Learning rate', 'Optimizer', 'Batch size',\n",
    "                  'Epoch'],\n",
    "    'Value':     ['mse', 'IoU', '0.05 (Reduce LR On Plateau to 0.000001)', 'Adam',\n",
    "                  '8', '300']\n",
    "    })\n",
    "pretext_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb0802-ea18-4f19-9eaa-8e66521111f4",
   "metadata": {},
   "source": [
    "## Detected faces - image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75b34b5-2efc-4ec2-aefe-c695a16055b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/test_faces.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1247c-5b1f-4393-884b-9b80d51acf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e4b85a-7e16-4f71-b0b5-333a6c855af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((1, 384, 384, 1)).astype('double')\n",
    "n = ts_df['name'].tolist()\n",
    "i = 99\n",
    "\n",
    "train_igg = image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + n[i], color_mode = \"grayscale\", target_size = (\n",
    "    384, 512))\n",
    "train_img = image.img_to_array(train_igg)\n",
    "train_img = train_img[:, 64:448]\n",
    "train_img /= 255.0\n",
    "img[0, :, :, :] = train_img\n",
    "img = np.array(img)\n",
    "\n",
    "faced = load_model('checkpoint_face')\n",
    "lbl_c = faced.predict(img)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (20, 10))\n",
    "ax.imshow(train_igg, cmap = 'gray')\n",
    "rect = patches.Rectangle((lbl_c[0][1] + 64, lbl_c[0][2]), (lbl_c[0][0] + 64 - lbl_c[0][1] - 64), (\n",
    "                       lbl_c[0][3] - lbl_c[0][2]), linewidth = 4, edgecolor = 'r', facecolor = 'none')\n",
    "ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e689a22-1e9e-4f62-bd0b-135483f31461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summ = 0\n",
    "\n",
    "for i in range(100):\n",
    "    start = time()\n",
    "    lbl_c = faced.predict(img)\n",
    "    end = time()\n",
    "\n",
    "    summ = summ + (end - start)\n",
    "\n",
    "print(summ / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c380ae8-f952-47c4-85bd-1402493d0fc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## IoU (comparison) - plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8766f0c6-1e1f-4bf3-83f2-9674d51df6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(ts_df):\n",
    "    n = ts_df.name.to_list()\n",
    "    images = np.empty((len(n), 384, 384, 1))\n",
    "    iou = np.zeros((len(n), 384, 384, 1), dtype = int)\n",
    "    face = np.empty((len(n), 4))\n",
    "\n",
    "    for i, ID in enumerate(n):\n",
    "        train_img = image.img_to_array(image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + ID, color_mode = \"grayscale\", target_size = (\n",
    "            384, 512)))\n",
    "        train_img = train_img[:, 64:448]\n",
    "        train_img /= 255.0\n",
    "        images[i,] = train_img\n",
    "\n",
    "        face[i, 0] = int(ts_df.iloc[i]['Xmax']) // 2\n",
    "        face[i, 1] = int(ts_df.iloc[i]['Xmin']) // 2\n",
    "        face[i, 2] = int(ts_df.iloc[i]['Ymin']) // 2\n",
    "        face[i, 3] = int(ts_df.iloc[i]['Ymax']) // 2\n",
    "\n",
    "        iou[i, int(face[i, 2]):int(face[i, 3]), int(face[i, 1]):int(face[i, 0]), 0] = 1\n",
    "\n",
    "    return images, iou\n",
    "\n",
    "\n",
    "x_test, y_true = image_generator(ts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23319f0c-3956-43ee-96b7-c54038b8add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = faced.predict(x_test, batch_size = 1, verbose = 1, steps = len(ts_df) // 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d4d3dd-b28a-4cb8-8b8d-5f029aa19c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_pred = np.zeros((len(predictions), 384, 384, 1), dtype = int)\n",
    "\n",
    "for idx, pred in enumerate(predictions):\n",
    "    iou_pred[idx, int(pred[2]):int(pred[3]), int(pred[1]):int(pred[0]), 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981254e2-1874-43ef-928a-fae5e39c73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.MeanIoU(num_classes = 2)\n",
    "m.update_state(y_true, iou_pred)\n",
    "mean_iou = m.result().numpy()\n",
    "\n",
    "print('mean iou: ', mean_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b4082f-c6b2-4ea7-8491-897e55517652",
   "metadata": {},
   "outputs": [],
   "source": [
    "each_iou = np.zeros((len(predictions)))\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    mymetric = tf.keras.metrics.MeanIoU(num_classes = 2)\n",
    "    mymetric.update_state(y_true[i], iou_pred[i])\n",
    "    each_iou[i] = mymetric.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c076a4-8bce-41c5-a6ad-936e82fa6bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.mean(each_iou)\n",
    "print(\"\\nMean: \", r1)\n",
    "\n",
    "r2 = np.std(each_iou)\n",
    "print(\"\\nstd: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862768d8-52a2-445d-b11f-2857010618b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_range = np.empty((11))\n",
    "\n",
    "for myidx, band in enumerate(np.arange(0, 1.1, 0.1)):\n",
    "    counter = 0\n",
    "\n",
    "    for mydata in each_iou:\n",
    "        if mydata > band:\n",
    "            counter = counter + 1\n",
    "\n",
    "    iou_range[myidx] = counter / len(each_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78fe79d-bae9-4e03-8051-9aa4f1a49334",
   "metadata": {},
   "outputs": [],
   "source": [
    "adrs = 'C:/Users/DrBah/Desktop/keypoint images/03 - Results/Face detection/04 IoU (comparison) - plot/'\n",
    "file = os.listdir(adrs)\n",
    "file.remove('1.png')\n",
    "file.remove('2.png')\n",
    "file.remove('3.png')\n",
    "\n",
    "plt.figure(figsize = (20, 15))\n",
    "\n",
    "mycsv = myy\n",
    "tmp = mycsv[0]\n",
    "for idx, mmbr in enumerate(mycsv):\n",
    "    if mmbr > tmp:\n",
    "        mycsv[idx] = tmp\n",
    "\n",
    "plt.plot(myx, mycsv, linewidth = 5, markersize = 12, label = 'our method')\n",
    "\n",
    "markers = ['|', 'v', '*', 's', 'x', 'D', 'p']\n",
    "\n",
    "for idxx, myfile in enumerate(file):\n",
    "    csv = pd.read_csv(adrs + myfile, header = None)\n",
    "\n",
    "    myx, myy = smoothing(csv[1].to_list())\n",
    "    mycsv = myy\n",
    "    plt.plot(myx, mycsv, linewidth = 5, markersize = 12, label = myfile[:-4])\n",
    "\n",
    "plt.xlabel('Intersection Over Union (IoU)', fontsize = 25)\n",
    "plt.ylabel('True positive (%)', fontsize = 25)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.legend(prop = {'size': 20})\n",
    "plt.axis([-0.01, 1, 0, 101])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1085ea5-faf3-4b14-a967-e4f8d399ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adrs = 'F:/Poorya/datasets/labels/new-labels/'\n",
    "up_lbl = pd.read_csv(adrs + 'output.csv')\n",
    "up_lbl.columns = ['name']\n",
    "\n",
    "files = os.listdir(adrs)\n",
    "files.remove('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003367df",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('F:/Poorya/datasets/ThermalFaceDatabase/main_df.csv')\n",
    "\n",
    "\n",
    "def df_to_ary(df):\n",
    "    ary = np.zeros((len(df), 136), dtype = int)\n",
    "    fth = np.zeros((len(df), 4), dtype = int)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        rep_x = [j for j in range(len(df['x'][i])) if df['x'][i].startswith(',', j)]\n",
    "        rep_y = [j for j in range(len(df['y'][i])) if df['y'][i].startswith(',', j)]\n",
    "        ary[i, 0] = int(df['x'][i][1:rep_x[0]]) / 2\n",
    "        ary[i, 67] = int(df['x'][i][rep_x[-1] + 1:-1]) / 2\n",
    "        ary[i, 68] = (int(df['y'][i][1:rep_y[0]]) - 128) / 2\n",
    "        ary[i, 135] = (int(df['y'][i][rep_y[-1] + 1:-1]) - 128) / 2\n",
    "        for k in range(66):\n",
    "            ary[i, k + 1] = int(df['x'][i][rep_x[k] + 1:rep_x[k + 1]]) / 2\n",
    "            ary[i, k + 69] = (int(df['y'][i][rep_y[k] + 1:rep_y[k + 1]]) - 128) / 2\n",
    "\n",
    "        fth[i, 2] = min(ary[i, :68])  # y1\n",
    "        fth[i, 3] = max(ary[i, :68])  # y2\n",
    "        fth[i, 1] = min(ary[i, 68:])  # x1\n",
    "        fth[i, 0] = max(ary[i, 68:])  # x2\n",
    "\n",
    "    return fth\n",
    "\n",
    "\n",
    "main_ary = df_to_ary(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((1, 384, 384, 1)).astype('double')\n",
    "i = 99\n",
    "\n",
    "train_igg = image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + main_df.iloc[i][\n",
    "    'images'], color_mode = \"grayscale\", target_size = (384, 512))\n",
    "train_img = image.img_to_array(train_igg)\n",
    "train_img = train_img[:, 64:448]\n",
    "train_img /= 255.0\n",
    "img[0, :, :, :] = train_img\n",
    "img = np.array(img)\n",
    "\n",
    "lbl_c = main_ary[i]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (20, 10))\n",
    "ax.imshow(train_igg, cmap = 'gray')\n",
    "rect = patches.Rectangle((lbl_c[1] + 64, lbl_c[2]), (lbl_c[0] + 64 - lbl_c[1] - 64), (\n",
    "                       lbl_c[3] - lbl_c[2]), linewidth = 4, edgecolor = 'r', facecolor = 'none')\n",
    "ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bffc077",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(columns = ['name', 'Xmax', 'Ymin', 'Xmin', 'Ymax'])\n",
    "\n",
    "for idx, img in enumerate(up_lbl.iloc):\n",
    "    sprt = img['name'].index(':')\n",
    "    index = main_df.isin([img['name'][:sprt]]).any(axis = 1).idxmax()\n",
    "    x1 = main_ary[index, 1]\n",
    "    x2 = main_ary[index, 0]\n",
    "    y2 = main_ary[index, 3]\n",
    "\n",
    "    test_df.loc[idx] = {\n",
    "        'name': img['name'][:sprt],\n",
    "        'Xmax': x2,\n",
    "        'Ymin': int(int(img['name'][sprt + 2:]) / 2),\n",
    "        'Xmin': x1,\n",
    "        'Ymax': y2\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf045c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((1, 384, 384, 1)).astype('double')\n",
    "test = test_df.iloc[10]\n",
    "\n",
    "train_igg = image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + test[\n",
    "    'name'], color_mode = \"grayscale\", target_size = (384, 512))\n",
    "train_img = image.img_to_array(train_igg)\n",
    "train_img = train_img[:, 64:448]\n",
    "train_img /= 255.0\n",
    "img[0, :, :, :] = train_img\n",
    "img = np.array(img)\n",
    "\n",
    "lbl_c = main_ary[i]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (20, 10))\n",
    "ax.imshow(train_igg, cmap = 'gray')\n",
    "rect = patches.Rectangle((test['Xmin'] + 64, test['Ymin']), (test['Xmax'] + 64 - test['Xmin'] - 64), (\n",
    "                       test['Ymax'] - test['Ymin']), linewidth = 4, edgecolor = 'r', facecolor = 'none')\n",
    "ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e76da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(ts_df):\n",
    "    n = ts_df.name.to_list()\n",
    "    images = np.empty((len(n), 384, 384, 1))\n",
    "    iou = np.zeros((len(n), 384, 384, 1), dtype = int)\n",
    "    face = np.empty((len(n), 4))\n",
    "\n",
    "    for i, ID in enumerate(n):\n",
    "        train_img = image.img_to_array(image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + ID, color_mode = \"grayscale\", target_size = (\n",
    "            384, 512)))\n",
    "        train_img = train_img[:, 64:448]\n",
    "        train_img /= 255.0\n",
    "        images[i,] = train_img\n",
    "\n",
    "        face[i, 0] = int(ts_df.iloc[i]['Xmax'])\n",
    "        face[i, 1] = int(ts_df.iloc[i]['Xmin'])\n",
    "        face[i, 2] = int(ts_df.iloc[i]['Ymin'])\n",
    "        face[i, 3] = int(ts_df.iloc[i]['Ymax'])\n",
    "\n",
    "        iou[i, int(face[i, 2]):int(face[i, 3]), int(face[i, 1]):int(face[i, 0]), 0] = 1\n",
    "\n",
    "    return images, iou\n",
    "\n",
    "\n",
    "x_test, y_true = image_generator(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b09ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[0])\n",
    "plt.show()\n",
    "plt.imshow(y_true[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a615ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "faced = load_model('checkpoint_face')\n",
    "predictions = faced.predict(x_test, batch_size = 1, verbose = 1, steps = len(test_df) // 1)\n",
    "iou_pred = np.zeros((len(predictions), 384, 384, 1), dtype = int)\n",
    "\n",
    "for idx, pred in enumerate(predictions):\n",
    "    iou_pred[idx, int(pred[2]):int(pred[3]), int(pred[1]):int(pred[0]), 0] = 1\n",
    "\n",
    "m = tf.keras.metrics.MeanIoU(num_classes = 2)\n",
    "m.update_state(y_true, iou_pred)\n",
    "mean_iou = m.result().numpy()\n",
    "\n",
    "print('mean iou: ', mean_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2bb1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "each_iou = np.zeros((len(predictions)))\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    mymetric = tf.keras.metrics.MeanIoU(num_classes = 2)\n",
    "    mymetric.update_state(y_true[i], iou_pred[i])\n",
    "    each_iou[i] = mymetric.result().numpy()\n",
    "\n",
    "r1 = np.mean(each_iou)\n",
    "print(\"\\nMean: \", r1)\n",
    "\n",
    "r2 = np.std(each_iou)\n",
    "print(\"\\nstd: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_range = np.empty((11))\n",
    "\n",
    "for myidx, band in enumerate(np.arange(0, 1.1, 0.1)):\n",
    "    counter = 0\n",
    "\n",
    "    for mydata in each_iou:\n",
    "        if mydata > band:\n",
    "            counter = counter + 1\n",
    "\n",
    "    iou_range[myidx] = counter / len(each_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb49aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "adrs = 'C:/Users/DrBah/Desktop/keypoint images/03 - Results/Face detection/04 IoU (comparison) - plot/'\n",
    "file = os.listdir(adrs)\n",
    "file.remove('1.png')\n",
    "\n",
    "plt.figure(figsize = (20, 15))\n",
    "plt.plot(np.arange(0, 1.1, 0.1), iou_range * 100, marker = \"o\", linewidth = 3, markersize = 12, label = 'our method')\n",
    "\n",
    "markers = ['|', 'v', '*', 's', 'x', 'D', 'p']\n",
    "\n",
    "for idxx, myfile in enumerate(file):\n",
    "    csv = pd.read_csv(adrs + myfile, header = None)\n",
    "    plt.plot(np.arange(0, 1.1, 0.1),\n",
    "             csv[1].to_list(), marker = markers[idxx], linewidth = 3, markersize = 12, label = myfile[:-4])\n",
    "\n",
    "plt.xlabel('Intersection Over Union (IoU)', fontsize = 25)\n",
    "plt.ylabel('True positive (%)', fontsize = 25)\n",
    "plt.rcParams.update({'font.size': 50})\n",
    "plt.legend(prop = {'size': 20})\n",
    "plt.axis([-0.01, 1, 0, 101])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5fbcdb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Keypoint detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55399d6",
   "metadata": {},
   "source": [
    "## keypoint model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a11c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretext_parameters = pd.DataFrame({\n",
    "    'Parameter': ['Loss', 'Metric', 'Learning rate', 'Optimizer', 'Batch size',\n",
    "                  'Epoch'],\n",
    "    'Value':     ['mse', 'Mean Absolute Percentage Error',\n",
    "                  '0.001 (Reduce LR On Plateau to 0.000001)', 'RMSprop', '2', '50']\n",
    "    })\n",
    "pretext_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe3a4da",
   "metadata": {},
   "source": [
    "## converge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadf9326",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Different tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e4ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc41d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "materials = ['Subject', 'Gender', 'Inpainting', 'Rotation', 'Inpainting + Rotation', 'Gender + Inpainting + Rotation',\n",
    "             'Our pretexts']\n",
    "x_pos = np.arange(len(materials))\n",
    "\n",
    "IoU_mean = [0.85, 0.89, 0.91, 0.92, 0.932, 0.939, 0.94]\n",
    "NME_mean = [2.22, 1.54, 1.74, 2.68, 1.44, 2.13, 1.29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1f8a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x_pos, IoU_mean, align = 'center', alpha = 0.5, ecolor = 'black', capsize = 10,\n",
    "       color = ['pink', 'orange', 'green', 'red', 'purple', 'olive', 'blue'])\n",
    "ax.set_ylabel('Intersection over Union (IoU)')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(materials)\n",
    "ax.yaxis.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04db0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x_pos, NME_mean, align = 'center', alpha = 0.5, ecolor = 'black', capsize = 10,\n",
    "       color = ['pink', 'orange', 'green', 'red', 'purple', 'olive', 'blue'])\n",
    "ax.set_ylabel('Normalized Mean Error (NME)')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(materials)\n",
    "ax.yaxis.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50131aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "adrs = 'C:/Users/DrBah/Desktop/keypoint images/03 - Results/Keypoint detection/05 NME for different pretexts - bar plot/'\n",
    "file = os.listdir(adrs)\n",
    "file.sort(key = len)\n",
    "\n",
    "plt.figure(figsize = (20, 15))\n",
    "\n",
    "for idxx, myfile in enumerate(file):\n",
    "    csv = np.load(adrs + myfile)\n",
    "    plt.plot(csv[0], csv[1], linewidth = 5, markersize = 12, label = myfile[:-4])\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.legend(prop = {'size': 20})\n",
    "plt.axis([0, 0.2, 0, 1])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5613841",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/test_kp.csv')\n",
    "\n",
    "\n",
    "def df_to_ary(df):\n",
    "    ary = np.zeros((len(df), 136), dtype = int)\n",
    "    for i in range(len(df)):\n",
    "        rep_x = [j for j in range(len(df['x'][i])) if df['x'][i].startswith(',', j)]\n",
    "        rep_y = [j for j in range(len(df['y'][i])) if df['y'][i].startswith(',', j)]\n",
    "        ary[i, 0] = int(df['x'][i][1:rep_x[0]]) / 2\n",
    "        ary[i, 67] = int(df['x'][i][rep_x[-1] + 1:-1]) / 2\n",
    "        ary[i, 68] = (int(df['y'][i][1:rep_y[0]]) - 128) / 2\n",
    "        ary[i, 135] = (int(df['y'][i][rep_y[-1] + 1:-1]) - 128) / 2\n",
    "        for k in range(66):\n",
    "            ary[i, k + 1] = int(df['x'][i][rep_x[k] + 1:rep_x[k + 1]]) / 2\n",
    "            ary[i, k + 69] = (int(df['y'][i][rep_y[k] + 1:rep_y[k + 1]]) - 128) / 2\n",
    "\n",
    "    return ary\n",
    "\n",
    "\n",
    "ts_ary = df_to_ary(ts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((1, 384, 384, 1)).astype('double')\n",
    "adrs = 'F:/Poorya/keypoint detection J/final codes/Pretexts/00 NME/'\n",
    "file = os.listdir(adrs)\n",
    "file.remove('Label.npy')\n",
    "\n",
    "train_igg = image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + ts_df['images'][\n",
    "    193], color_mode = \"grayscale\", target_size = (384, 512))\n",
    "train_img = image.img_to_array(train_igg)\n",
    "train_img /= 255.0\n",
    "img[0, :, :, :] = train_img[:, 64:448]\n",
    "img = np.array(img)\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.imshow(img[0], cmap = 'gray')\n",
    "\n",
    "lbl = np.load(adrs + 'Label.npy')\n",
    "plt.scatter(lbl[68:], lbl[0:68], label = 'Label')\n",
    "\n",
    "for idx, myfile in enumerate(file):\n",
    "    lbl = np.load(adrs + myfile)\n",
    "    plt.scatter(lbl[0][68:], lbl[0][0:68], label = myfile[:-4])\n",
    "\n",
    "plt.axis([100, 290, 220, 350])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "\n",
    "def PSNR(super_resolution, high_resolution):\n",
    "    psnr_value = tf.image.psnr(high_resolution, super_resolution, max_val = 1)[0]\n",
    "    return psnr_value\n",
    "\n",
    "\n",
    "def SSIMLoss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "\n",
    "img = np.zeros((1, 384, 384, 1)).astype('double')\n",
    "train_igg = image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + ts_df['images'][\n",
    "    193], color_mode = \"grayscale\", target_size = (384, 512))\n",
    "train_img = image.img_to_array(train_igg)\n",
    "train_img /= 255.0\n",
    "img[0, :, :, :] = train_img[:, 64:448]\n",
    "img = np.array(img)\n",
    "\n",
    "model = load_model('checkpoint_loss6', custom_objects = {'PSNR': PSNR, 'SSIMLoss': SSIMLoss})\n",
    "fe_model = Model(inputs = model.inputs, outputs = model.layers[12].output)  # 4, ..., 24\n",
    "\n",
    "activation = fe_model(img)\n",
    "\n",
    "plt.figure(figsize = (20, 20))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(activation[0, :, :, i])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poorya kernel",
   "language": "python",
   "name": "poorya"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
