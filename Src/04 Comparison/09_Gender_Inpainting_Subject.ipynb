{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d8e00c2",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f592ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e27fc82",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe4926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D, Flatten\n",
    "from tensorflow.keras.layers import AveragePooling2D, BatchNormalization, Conv2DTranspose\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from livelossplot.inputs.tf_keras import PlotLossesCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a38f1b6",
   "metadata": {},
   "source": [
    "# Pretext training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17adbcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = []\n",
    "my_subjects = {}\n",
    "counter = 0\n",
    "\n",
    "files = os.listdir('F:/poorya/datasets/keypoint J dataset/pretext dataset/train_aug/')\n",
    "\n",
    "for i in files:\n",
    "    sub.append(i[-6:-4])\n",
    "\n",
    "for i in range(95):\n",
    "    if str(i).zfill(2) in sub:\n",
    "        my_subjects[str(i).zfill(2)] = counter\n",
    "        counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a10eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pretext_DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, folder, batch_size, my_subjects):\n",
    "        self.folder = folder\n",
    "        self.n = os.listdir(folder)\n",
    "        self.batch_size = batch_size\n",
    "        self.my_subjects = my_subjects\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.n) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        list_IDs_temp = [self.n[k] for k in indexes]\n",
    "        x, y = self.__data_generation(list_IDs_temp)\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.n))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        images = np.empty((self.batch_size, 384, 384, 1))\n",
    "        masks = np.empty((self.batch_size, 48, 48, 1))\n",
    "        rotation = np.empty((self.batch_size), dtype = int)\n",
    "        subject = np.empty((self.batch_size), dtype = int)\n",
    "        gender = np.empty((self.batch_size), dtype = int)\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "\n",
    "            train_img_1 = image.img_to_array(image.load_img(self.folder + ID, color_mode = \"grayscale\", target_size = (\n",
    "            384, 384)))\n",
    "            train_img_1 /= 255.0\n",
    "            masks[i,] = train_img_1[168:216, 168:216]\n",
    "\n",
    "            train_img_2 = image.img_to_array(image.load_img(self.folder + ID, color_mode = \"grayscale\", target_size = (\n",
    "            384, 384)))\n",
    "            train_img_2 /= 255.0\n",
    "            train_img_2[168:216, 168:216] = 0\n",
    "            images[i,] = train_img_2\n",
    "\n",
    "            rotation[i] = int(ID[-10])\n",
    "            subject[i] = int(self.my_subjects[ID[-6:-4]])\n",
    "            gender[i] = int(ID[-8])\n",
    "\n",
    "        return images, [to_categorical(gender, num_classes = 2), to_categorical(subject, num_classes = 89), masks]\n",
    "\n",
    "\n",
    "#  [to_categorical(gender, num_classes=2), to_categorical(rotation, num_classes=4), to_categorical(subject, num_classes=89), masks]\n",
    "\n",
    "\n",
    "bs = 16\n",
    "train_gen = Pretext_DataGenerator('F:/poorya/datasets/keypoint J dataset/pretext dataset/train_aug/', bs, my_subjects)\n",
    "val_gen = Pretext_DataGenerator('F:/poorya/datasets/keypoint J dataset/pretext dataset/val/', bs, my_subjects)\n",
    "test_gen = Pretext_DataGenerator('F:/poorya/datasets/keypoint J dataset/pretext dataset/test/', bs, my_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6591c72f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def vgg_block(layer_in, n_filters, n_conv):\n",
    "    for _ in range(n_conv):\n",
    "        layer_in = Conv2D(n_filters, (3, 3), padding = 'same', activation = 'relu')(layer_in)\n",
    "    layer_in = BatchNormalization()(layer_in)\n",
    "    layer_in = AveragePooling2D((2, 2), strides = (2, 2))(layer_in)\n",
    "    return layer_in\n",
    "\n",
    "\n",
    "def PSNR(super_resolution, high_resolution):\n",
    "    psnr_value = tf.image.psnr(high_resolution, super_resolution, max_val = 1)[0]\n",
    "    return psnr_value\n",
    "\n",
    "\n",
    "def SSIMLoss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    ######################################  INITIALIZATION  ########################################\n",
    "\n",
    "    loss_list = {'gender': 'categorical_crossentropy', 'subject': 'categorical_crossentropy', 'mask': 'mse'}\n",
    "    test_metrics = {'gender': 'accuracy', 'subject': 'accuracy', 'mask': PSNR}\n",
    "    opt = tf.keras.optimizers.RMSprop(learning_rate = 0.01)\n",
    "    drp = 0.1\n",
    "    act = 'relu'\n",
    "    eact = 'softmax'\n",
    "    s = 'same'\n",
    "\n",
    "    ########################################  BACKBONE  ############################################\n",
    "\n",
    "    model_input = Input(shape = (384, 384, 1))\n",
    "\n",
    "    layer = vgg_block(model_input, 8, 2)\n",
    "    layer = vgg_block(layer, 16, 2)\n",
    "    layer = vgg_block(layer, 32, 2)\n",
    "    layer = vgg_block(layer, 64, 2)\n",
    "    layer = vgg_block(layer, 128, 2)\n",
    "    layer = vgg_block(layer, 256, 2)\n",
    "\n",
    "    ###################################  CLASSIFICATIONS  ##########################################\n",
    "\n",
    "    x = Flatten()(layer)\n",
    "    x = Dense(512, activation = act)(x)\n",
    "    x = Dropout(drp)(x)\n",
    "\n",
    "    y1 = Dense(256, activation = act)(x)\n",
    "    y1 = Dropout(drp)(y1)\n",
    "    y1 = Dense(128, activation = act)(y1)\n",
    "    y1 = Dropout(drp)(y1)\n",
    "    y1 = Dense(2, activation = eact, name = 'gender')(y1)\n",
    "\n",
    "    #y2= Dense(256, activation=act)(x)\n",
    "    #y2= Dropout(drp)(y2)\n",
    "    #y2= Dense(128, activation=act)(y2)\n",
    "    #y2= Dropout(drp)(y2)\n",
    "    #y2= Dense(  4, activation=eact, name='rotation')(y2)\n",
    "\n",
    "    y3 = Dense(256, activation = act)(x)\n",
    "    y3 = Dropout(drp)(y3)\n",
    "    y3 = Dense(128, activation = act)(y3)\n",
    "    y3 = Dropout(drp)(y3)\n",
    "    y3 = Dense(89, activation = eact, name = 'subject')(y3)\n",
    "\n",
    "    ########################################  DECODER  ############################################\n",
    "\n",
    "    y4 = Conv2DTranspose(256, (3, 3), strides = (2, 2), activation = act, padding = s)(layer)\n",
    "    y4 = Conv2D(256, (3, 3), activation = act, padding = s)(y4)\n",
    "    y4 = Conv2D(256, (3, 3), activation = act, padding = s)(y4)\n",
    "    y4 = BatchNormalization()(y4)\n",
    "    y4 = Dropout(0.5)(y4)\n",
    "\n",
    "    y4 = Conv2DTranspose(64, (3, 3), strides = (2, 2), activation = act, padding = s)(y4)\n",
    "    y4 = Conv2D(64, (3, 3), activation = act, padding = s)(y4)\n",
    "    y4 = Conv2D(64, (3, 3), activation = act, padding = s)(y4)\n",
    "    y4 = BatchNormalization()(y4)\n",
    "    y4 = Dropout(0.5)(y4)\n",
    "\n",
    "    y4 = Conv2DTranspose(16, (3, 3), strides = (2, 2), activation = act, padding = s)(y4)\n",
    "    y4 = Conv2D(16, (3, 3), activation = act, padding = s)(y4)\n",
    "    y4 = Conv2D(16, (3, 3), activation = act, padding = s)(y4)\n",
    "    y4 = BatchNormalization()(y4)\n",
    "    y4 = Dropout(0.5)(y4)\n",
    "\n",
    "    y4 = Conv2D(1, (1, 1), padding = s, name = 'mask')(y4)\n",
    "\n",
    "    model = Model(inputs = model_input, outputs = [y1, y3, y4])\n",
    "    model.compile(loss = loss_list, optimizer = opt, metrics = test_metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554d2da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tr():\n",
    "    chk_loss = ModelCheckpoint(filepath = 'checkpoint_pretext_01', monitor = 'val_loss', mode = 'min', verbose = 1, save_best_only = True)\n",
    "    early_st = EarlyStopping(monitor = \"val_loss\", patience = 30, verbose = 1, mode = \"min\")\n",
    "    rduce_lr = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.5, patience = 5, verbose = 1, mode = \"min\", min_lr = 0.000001)\n",
    "    tr_plot = PlotLossesCallback()\n",
    "    return [chk_loss, rduce_lr, tr_plot]\n",
    "\n",
    "\n",
    "cll = tr()\n",
    "history = model.fit(train_gen,\n",
    "                    validation_data = val_gen,\n",
    "                    batch_size = bs,\n",
    "                    epochs = 100,\n",
    "                    verbose = 1,\n",
    "                    callbacks = cll,\n",
    "                    steps_per_epoch = len(os.listdir('F:/poorya/datasets/keypoint J dataset/pretext dataset/train_aug/')) // bs,\n",
    "                    validation_steps = len(os.listdir('F:/poorya/datasets/keypoint J dataset/pretext dataset/val/')) // bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d529a84",
   "metadata": {},
   "source": [
    "# Face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f44d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/train_faces.csv')\n",
    "ts_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/test_faces.csv')\n",
    "vl_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/val_faces.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd5848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Face_DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, batch_size):\n",
    "        self.n = df['name'].tolist()\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.n) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        list_IDs_temp = [self.n[k] for k in indexes]\n",
    "        x, y = self.__data_generation(list_IDs_temp, indexes)\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.n))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp, indexes):\n",
    "        images = np.empty((self.batch_size, 384, 384, 1))\n",
    "        face = np.empty((self.batch_size, 4))\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            train_img = image.img_to_array(image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + ID, color_mode = \"grayscale\", target_size = (\n",
    "            384, 512)))\n",
    "            train_img = train_img[:, 64:448]\n",
    "            train_img /= 255.0\n",
    "            images[i,] = train_img\n",
    "\n",
    "            face[i, 0] = int(self.df.iloc[indexes[i]]['Xmax']) // 2\n",
    "            face[i, 1] = int(self.df.iloc[indexes[i]]['Xmin']) // 2\n",
    "            face[i, 2] = int(self.df.iloc[indexes[i]]['Ymin']) // 2\n",
    "            face[i, 3] = int(self.df.iloc[indexes[i]]['Ymax']) // 2\n",
    "\n",
    "        return images, face\n",
    "\n",
    "\n",
    "bs = 8\n",
    "train_gen = Face_DataGenerator(tr_df, bs)\n",
    "val_gen = Face_DataGenerator(vl_df, bs)\n",
    "test_gen = Face_DataGenerator(ts_df, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cabe9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(super_resolution, high_resolution):\n",
    "    psnr_value = tf.image.psnr(high_resolution, super_resolution, max_val = 1)[0]\n",
    "    return psnr_value\n",
    "\n",
    "\n",
    "def SSIMLoss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    ######################################  INITIALIZATION  ########################################\n",
    "\n",
    "    metrics = [tf.keras.metrics.MeanAbsolutePercentageError()]\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 0.05)\n",
    "    loss = tf.keras.losses.MeanSquaredError()\n",
    "    drp = 0.0\n",
    "    act = 'relu'\n",
    "\n",
    "    ########################################  BACKBONE  ############################################\n",
    "    img_input = Input(shape = (384, 384, 1))\n",
    "\n",
    "    full_model = load_model('checkpoint_pretext_01', custom_objects = {'PSNR': PSNR, 'SSIMLoss': SSIMLoss})\n",
    "    model = Model(inputs = full_model.inputs, outputs = full_model.layers[24].output)\n",
    "    model.trainable = False\n",
    "    model.summary()\n",
    "\n",
    "    x = model(img_input)\n",
    "    ########################################  FLATTEN  #############################################\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(128, kernel_initializer = 'normal', activation = act)(x)\n",
    "    x = Dropout(drp)(x)\n",
    "\n",
    "    last = Dense(4)(x)\n",
    "\n",
    "    modell = Model(inputs = img_input, outputs = last)\n",
    "    modell.compile(loss = loss, optimizer = opt, metrics = metrics)\n",
    "\n",
    "    return modell\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289a9594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr():\n",
    "    chk = ModelCheckpoint(filepath = 'checkpoint_face_01', monitor = 'val_loss', mode = 'min', verbose = 1, save_best_only = True)\n",
    "    ers = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 20)\n",
    "    rduce_lr = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.5, patience = 5, verbose = 1, mode = \"min\", min_lr = 0.000001)\n",
    "    vk = PlotLossesCallback()\n",
    "    return [chk, vk, rduce_lr, ers]\n",
    "\n",
    "\n",
    "cll = tr()\n",
    "history = model.fit(train_gen,\n",
    "                    validation_data = val_gen,\n",
    "                    batch_size = bs,\n",
    "                    epochs = 100,\n",
    "                    verbose = 1,\n",
    "                    callbacks = cll,\n",
    "                    steps_per_epoch = len(tr_df) // bs,\n",
    "                    validation_steps = len(vl_df) // bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2578c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(ts_df):\n",
    "    n = ts_df.name.to_list()\n",
    "    images = np.empty((len(n), 384, 384, 1))\n",
    "    iou = np.zeros((len(n), 384, 384, 1), dtype = int)\n",
    "    face = np.empty((len(n), 4))\n",
    "\n",
    "    for i, ID in enumerate(n):\n",
    "        train_img = image.img_to_array(image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + ID, color_mode = \"grayscale\", target_size = (\n",
    "        384, 512)))\n",
    "        train_img = train_img[:, 64:448]\n",
    "        train_img /= 255.0\n",
    "        images[i,] = train_img\n",
    "\n",
    "        face[i, 0] = int(ts_df.iloc[i]['Xmax']) // 2\n",
    "        face[i, 1] = int(ts_df.iloc[i]['Xmin']) // 2\n",
    "        face[i, 2] = int(ts_df.iloc[i]['Ymin']) // 2\n",
    "        face[i, 3] = int(ts_df.iloc[i]['Ymax']) // 2\n",
    "\n",
    "        iou[i, int(face[i, 2]):int(face[i, 3]), int(face[i, 1]):int(face[i, 0]), 0] = 1\n",
    "\n",
    "    return images, iou\n",
    "\n",
    "\n",
    "ts_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/test_faces.csv')\n",
    "x_test, y_true = image_generator(ts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2193fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "faced = load_model('checkpoint_face_01')\n",
    "predictions = faced.predict(x_test, batch_size = 1, verbose = 1, steps = len(ts_df) // 1)\n",
    "iou_pred = np.zeros((len(predictions), 384, 384, 1), dtype = int)\n",
    "\n",
    "for idx, pred in enumerate(predictions):\n",
    "    iou_pred[idx, int(pred[2]):int(pred[3]), int(pred[1]):int(pred[0]), 0] = 1\n",
    "\n",
    "m = tf.keras.metrics.MeanIoU(num_classes = 2)\n",
    "m.update_state(y_true, iou_pred)\n",
    "mean_iou = m.result().numpy()\n",
    "\n",
    "print('mean iou: ', mean_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ac511",
   "metadata": {},
   "outputs": [],
   "source": [
    "each_iou = np.zeros((len(predictions)))\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    mymetric = tf.keras.metrics.MeanIoU(num_classes = 2)\n",
    "    mymetric.update_state(y_true[i], iou_pred[i])\n",
    "    each_iou[i] = mymetric.result().numpy()\n",
    "\n",
    "r1 = np.mean(each_iou)\n",
    "print(\"\\nMean: \", r1)\n",
    "\n",
    "r2 = np.std(each_iou)\n",
    "print(\"\\nstd: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e432ab6",
   "metadata": {},
   "source": [
    "# Keypoint detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883a207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/train_kp.csv')\n",
    "vl_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/val_kp.csv')\n",
    "ts_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/test_kp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb14d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_ary(df):\n",
    "    ary = np.zeros((len(df), 136), dtype = int)\n",
    "    for i in range(len(df)):\n",
    "        rep_x = [j for j in range(len(df['x'][i])) if df['x'][i].startswith(',', j)]\n",
    "        rep_y = [j for j in range(len(df['y'][i])) if df['y'][i].startswith(',', j)]\n",
    "        ary[i, 0] = int(df['x'][i][1:rep_x[0]]) / 2\n",
    "        ary[i, 67] = int(df['x'][i][rep_x[-1] + 1:-1]) / 2\n",
    "        ary[i, 68] = (int(df['y'][i][1:rep_y[0]]) - 128) / 2\n",
    "        ary[i, 135] = (int(df['y'][i][rep_y[-1] + 1:-1]) - 128) / 2\n",
    "        for k in range(66):\n",
    "            ary[i, k + 1] = int(df['x'][i][rep_x[k] + 1:rep_x[k + 1]]) / 2\n",
    "            ary[i, k + 69] = (int(df['y'][i][rep_y[k] + 1:rep_y[k + 1]]) - 128) / 2\n",
    "\n",
    "    return ary\n",
    "\n",
    "\n",
    "tr_ary = df_to_ary(tr_df)\n",
    "ts_ary = df_to_ary(ts_df)\n",
    "vl_ary = df_to_ary(vl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143bd91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_partition(x, window_size):\n",
    "    _, height, width, channels = x.shape\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(\n",
    "        x, shape = (-1, patch_num_y, window_size, patch_num_x, window_size, channels)\n",
    "        )\n",
    "    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n",
    "    windows = tf.reshape(x, shape = (-1, window_size, window_size, channels))\n",
    "    return windows\n",
    "\n",
    "\n",
    "def window_reverse(windows, window_size, height, width, channels):\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(\n",
    "        windows,\n",
    "        shape = (-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n",
    "        )\n",
    "    x = tf.transpose(x, perm = (0, 1, 3, 2, 4, 5))\n",
    "    x = tf.reshape(x, shape = (-1, height, width, channels))\n",
    "    return x\n",
    "\n",
    "\n",
    "class DropPath(layers.Layer):\n",
    "    def __init__(self, drop_prob=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def call(self, x):\n",
    "        input_shape = tf.shape(x)\n",
    "        batch_size = input_shape[0]\n",
    "        rank = x.shape.rank\n",
    "        shape = (batch_size,) + (1,) * (rank - 1)\n",
    "        random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape, dtype = x.dtype)\n",
    "        path_mask = tf.floor(random_tensor)\n",
    "        output = tf.math.divide(x, 1 - self.drop_prob) * path_mask\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817fad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowAttention(layers.Layer):\n",
    "    def __init__(\n",
    "        self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs\n",
    "        ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "        self.qkv = layers.Dense(dim * 3, use_bias = qkv_bias)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.proj = layers.Dense(dim)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        num_window_elements = (2 * self.window_size[0] - 1) * (\n",
    "                               2 * self.window_size[1] - 1\n",
    "        )\n",
    "        self.relative_position_bias_table = self.add_weight(\n",
    "            name = 'W',\n",
    "            shape = (num_window_elements, self.num_heads),\n",
    "            initializer = tf.initializers.Zeros(),\n",
    "            trainable = True,\n",
    "            )\n",
    "        coords_h = np.arange(self.window_size[0])\n",
    "        coords_w = np.arange(self.window_size[1])\n",
    "        coords_matrix = np.meshgrid(coords_h, coords_w, indexing = \"ij\")\n",
    "        coords = np.stack(coords_matrix)\n",
    "        coords_flatten = coords.reshape(2, -1)\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = relative_coords.transpose([1, 2, 0])\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)\n",
    "\n",
    "        self.relative_position_index = tf.Variable(\n",
    "            initial_value = tf.convert_to_tensor(relative_position_index), trainable = False\n",
    "            )\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        _, size, channels = x.shape\n",
    "        head_dim = channels // self.num_heads\n",
    "        x_qkv = self.qkv(x)\n",
    "        x_qkv = tf.reshape(x_qkv, shape = (-1, size, 3, self.num_heads, head_dim))\n",
    "        x_qkv = tf.transpose(x_qkv, perm = (2, 0, 3, 1, 4))\n",
    "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
    "        q = q * self.scale\n",
    "        k = tf.transpose(k, perm = (0, 1, 3, 2))\n",
    "        attn = q @ k\n",
    "\n",
    "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
    "        relative_position_index_flat = tf.reshape(\n",
    "            self.relative_position_index, shape = (-1,)\n",
    "            )\n",
    "        relative_position_bias = tf.gather(\n",
    "            self.relative_position_bias_table, relative_position_index_flat\n",
    "            )\n",
    "        relative_position_bias = tf.reshape(\n",
    "            relative_position_bias, shape = (num_window_elements, num_window_elements, -1)\n",
    "            )\n",
    "        relative_position_bias = tf.transpose(relative_position_bias, perm = (2, 0, 1))\n",
    "        attn = attn + tf.expand_dims(relative_position_bias, axis = 0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.get_shape()[0]\n",
    "            mask_float = tf.cast(\n",
    "                tf.expand_dims(tf.expand_dims(mask, axis = 1), axis = 0), tf.float32\n",
    "                )\n",
    "            attn = (\n",
    "                                   tf.reshape(attn, shape = (-1, nW, self.num_heads, size, size))\n",
    "                                   + mask_float\n",
    "            )\n",
    "            attn = tf.reshape(attn, shape = (-1, self.num_heads, size, size))\n",
    "            attn = keras.activations.softmax(attn, axis = -1)\n",
    "        else:\n",
    "            attn = keras.activations.softmax(attn, axis = -1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        x_qkv = attn @ v\n",
    "        x_qkv = tf.transpose(x_qkv, perm = (0, 2, 1, 3))\n",
    "        x_qkv = tf.reshape(x_qkv, shape = (-1, size, channels))\n",
    "        x_qkv = self.proj(x_qkv)\n",
    "        x_qkv = self.dropout(x_qkv)\n",
    "        return x_qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e8911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformer(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_patch,\n",
    "        num_heads,\n",
    "        window_size=7,\n",
    "        shift_size=0,\n",
    "        num_mlp=1024,\n",
    "        qkv_bias=True,\n",
    "        dropout_rate=0.0,\n",
    "        **kwargs,\n",
    "        ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.dim = dim  # number of input dimensions\n",
    "        self.num_patch = num_patch  # number of embedded patches\n",
    "        self.num_heads = num_heads  # number of attention heads\n",
    "        self.window_size = window_size  # size of window\n",
    "        self.shift_size = shift_size  # size of window shift\n",
    "        self.num_mlp = num_mlp  # number of MLP nodes\n",
    "\n",
    "        self.norm1 = layers.LayerNormalization(epsilon = 1e-5)\n",
    "        self.attn = WindowAttention(\n",
    "            dim,\n",
    "            window_size = (self.window_size, self.window_size),\n",
    "            num_heads = num_heads,\n",
    "            qkv_bias = qkv_bias,\n",
    "            dropout_rate = dropout_rate,\n",
    "            )\n",
    "        self.drop_path = DropPath(dropout_rate)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon = 1e-5)\n",
    "\n",
    "        self.mlp = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(num_mlp),\n",
    "                layers.Activation(keras.activations.gelu),\n",
    "                layers.Dropout(dropout_rate),\n",
    "                layers.Dense(dim),\n",
    "                layers.Dropout(dropout_rate),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        if min(self.num_patch) < self.window_size:\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.num_patch)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.shift_size == 0:\n",
    "            self.attn_mask = None\n",
    "        else:\n",
    "            height, width = self.num_patch\n",
    "            h_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "                )\n",
    "            w_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "                )\n",
    "            mask_array = np.zeros((1, height, width, 1))\n",
    "            count = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    mask_array[:, h, w, :] = count\n",
    "                    count += 1\n",
    "            mask_array = tf.convert_to_tensor(mask_array)\n",
    "\n",
    "            # mask array to windows\n",
    "            mask_windows = window_partition(mask_array, self.window_size)\n",
    "            mask_windows = tf.reshape(\n",
    "                mask_windows, shape = [-1, self.window_size * self.window_size]\n",
    "                )\n",
    "            attn_mask = tf.expand_dims(mask_windows, axis = 1) - tf.expand_dims(\n",
    "                mask_windows, axis = 2\n",
    "                )\n",
    "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
    "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
    "            self.attn_mask = tf.Variable(initial_value = attn_mask, trainable = False)\n",
    "\n",
    "    def call(self, x):\n",
    "        height, width = self.num_patch\n",
    "        _, num_patches_before, channels = x.shape\n",
    "        x_skip = x\n",
    "        x = self.norm1(x)\n",
    "        x = tf.reshape(x, shape = (-1, height, width, channels))\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = tf.roll(\n",
    "                x, shift = [-self.shift_size, -self.shift_size], axis = [1, 2]\n",
    "                )\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        x_windows = window_partition(shifted_x, self.window_size)\n",
    "        x_windows = tf.reshape(\n",
    "            x_windows, shape = (-1, self.window_size * self.window_size, channels)\n",
    "            )\n",
    "        attn_windows = self.attn(x_windows, mask = self.attn_mask)\n",
    "\n",
    "        attn_windows = tf.reshape(\n",
    "            attn_windows, shape = (-1, self.window_size, self.window_size, channels)\n",
    "            )\n",
    "        shifted_x = window_reverse(\n",
    "            attn_windows, self.window_size, height, width, channels\n",
    "            )\n",
    "        if self.shift_size > 0:\n",
    "            x = tf.roll(\n",
    "                shifted_x, shift = [self.shift_size, self.shift_size], axis = [1, 2]\n",
    "                )\n",
    "        else:\n",
    "            x = shifted_x\n",
    "\n",
    "        x = tf.reshape(x, shape = (-1, height * width, channels))\n",
    "        x = self.drop_path(x)\n",
    "        x = x_skip + x\n",
    "        x_skip = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = self.drop_path(x)\n",
    "        x = x_skip + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a7ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchExtract(layers.Layer):\n",
    "    def __init__(self, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.patch_size_x = patch_size[0]\n",
    "        self.patch_size_y = patch_size[0]\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images = images,\n",
    "            sizes = (1, self.patch_size_x, self.patch_size_y, 1),\n",
    "            strides = (1, self.patch_size_x, self.patch_size_y, 1),\n",
    "            rates = (1, 1, 1, 1),\n",
    "            padding = \"VALID\",\n",
    "            )\n",
    "        patch_dim = patches.shape[-1]\n",
    "        patch_num = patches.shape[1]\n",
    "        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n",
    "\n",
    "\n",
    "class PatchEmbedding(layers.Layer):\n",
    "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_patch = num_patch\n",
    "        self.proj = layers.Dense(embed_dim)\n",
    "        self.pos_embed = layers.Embedding(input_dim = num_patch, output_dim = embed_dim)\n",
    "\n",
    "    def call(self, patch):\n",
    "        pos = tf.range(start = 0, limit = self.num_patch, delta = 1)\n",
    "        return self.proj(patch) + self.pos_embed(pos)\n",
    "\n",
    "\n",
    "class PatchMerging(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_patch, embed_dim):\n",
    "        super().__init__()\n",
    "        self.num_patch = num_patch\n",
    "        self.embed_dim = embed_dim\n",
    "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias = False)\n",
    "\n",
    "    def call(self, x):\n",
    "        height, width = self.num_patch\n",
    "        _, _, C = x.get_shape().as_list()\n",
    "        x = tf.reshape(x, shape = (-1, height, width, C))\n",
    "        x0 = x[:, 0::2, 0::2, :]\n",
    "        x1 = x[:, 1::2, 0::2, :]\n",
    "        x2 = x[:, 0::2, 1::2, :]\n",
    "        x3 = x[:, 1::2, 1::2, :]\n",
    "        x = tf.concat((x0, x1, x2, x3), axis = -1)\n",
    "        x = tf.reshape(x, shape = (-1, (height // 2) * (width // 2), 4 * C))\n",
    "        return self.linear_trans(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301704ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, ary, batch_size):\n",
    "        self.n = df['images'].tolist()\n",
    "        self.df = df\n",
    "        self.ary = ary\n",
    "        self.batch_size = batch_size\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.n) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        list_IDs_temp = [self.n[k] for k in indexes]\n",
    "        x, y = self.__data_generation(list_IDs_temp, indexes)\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.n))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp, indexes):\n",
    "        images = np.empty((self.batch_size, 384, 384, 1))\n",
    "        kp = np.empty((self.batch_size, 136))\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            train_img = image.img_to_array(image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + ID, color_mode = \"grayscale\", target_size = (\n",
    "            384, 512)))\n",
    "            train_img = train_img[:, 64:448]\n",
    "            train_img /= 255.0\n",
    "            images[i,] = train_img\n",
    "\n",
    "            kp[i,] = self.ary[indexes[i], :]\n",
    "\n",
    "        return images, kp\n",
    "\n",
    "\n",
    "bs = 2\n",
    "train_gen = DataGenerator(tr_df, tr_ary, bs)\n",
    "val_gen = DataGenerator(vl_df, vl_ary, bs)\n",
    "test_gen = DataGenerator(ts_df, ts_ary, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(super_resolution, high_resolution):\n",
    "    psnr_value = tf.image.psnr(high_resolution, super_resolution, max_val = 255)[0]\n",
    "    return psnr_value\n",
    "\n",
    "\n",
    "def SSIMLoss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    ######################################  INITIALIZATION  ########################################\n",
    "\n",
    "    patch_size = (2, 2)\n",
    "    num_heads = 8\n",
    "    embed_dim = 64\n",
    "    qkv_bias = True\n",
    "    window_size = 2\n",
    "    shift_size = 1\n",
    "    image_dimension = 384\n",
    "    num_mlp = 512\n",
    "    dropout_rate = 0.1\n",
    "\n",
    "    num_patch_x = 384 // patch_size[0]\n",
    "    num_patch_y = 384 // patch_size[1]\n",
    "\n",
    "    weight_decay = 0.0001\n",
    "    label_smoothing = 0.05\n",
    "\n",
    "    drp = 0.0\n",
    "    act = 'relu'\n",
    "\n",
    "    ########################################  BACKBONE  ############################################\n",
    "\n",
    "    img_input = Input(shape = (384, 384, 1))\n",
    "\n",
    "    full_model = load_model('checkpoint_pretext_01', custom_objects = {'PSNR': PSNR, 'SSIMLoss': SSIMLoss})\n",
    "    model = Model(inputs = full_model.inputs, outputs = full_model.layers[24].output)\n",
    "    model.trainable = False\n",
    "\n",
    "    x = model(img_input)\n",
    "    x1 = Flatten()(x)\n",
    "\n",
    "    #########################################  SWIN T  #############################################\n",
    "\n",
    "    x = layers.experimental.preprocessing.RandomCrop(image_dimension, image_dimension)(img_input)\n",
    "    x = layers.experimental.preprocessing.RandomFlip(\"horizontal\")(x)\n",
    "    x = PatchExtract(patch_size)(x)\n",
    "    x = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(x)\n",
    "    x = SwinTransformer(\n",
    "        dim = embed_dim,\n",
    "        num_patch = (num_patch_x, num_patch_y),\n",
    "        num_heads = num_heads,\n",
    "        window_size = window_size,\n",
    "        shift_size = 0,\n",
    "        num_mlp = num_mlp,\n",
    "        qkv_bias = qkv_bias,\n",
    "        dropout_rate = dropout_rate)(x)\n",
    "    x = SwinTransformer(\n",
    "        dim = embed_dim,\n",
    "        num_patch = (num_patch_x, num_patch_y),\n",
    "        num_heads = num_heads,\n",
    "        window_size = window_size,\n",
    "        shift_size = shift_size,\n",
    "        num_mlp = num_mlp,\n",
    "        qkv_bias = qkv_bias,\n",
    "        dropout_rate = dropout_rate)(x)\n",
    "    x = PatchMerging((num_patch_x, num_patch_y), embed_dim = embed_dim)(x)\n",
    "    x2 = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    ########################################  FLATTEN  ############################################\n",
    "\n",
    "    x = layers.Concatenate()([x1, x2])\n",
    "\n",
    "    x = Dense(1024, activation = act)(x)\n",
    "    x = Dropout(drp)(x)\n",
    "    x = Dense(512, activation = act)(x)\n",
    "    x = Dropout(drp)(x)\n",
    "\n",
    "    last = Dense(136)(x)\n",
    "\n",
    "    return Model(inputs = img_input, outputs = last)\n",
    "\n",
    "\n",
    "metrics = [tf.keras.metrics.MeanAbsolutePercentageError()]\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate = 0.001)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "model = get_model()\n",
    "model.compile(loss = loss, optimizer = opt, metrics = metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec64ffc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tr():\n",
    "    chk = ModelCheckpoint(filepath = 'checkpoint_keypoint_01', monitor = 'val_loss', mode = 'min', verbose = 1, save_best_only = True)\n",
    "    ers = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 8)\n",
    "    rduce_lr = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.5, patience = 5, verbose = 1, mode = \"min\", min_lr = 0.000001)\n",
    "    vk = PlotLossesCallback()\n",
    "    lgg = tf.keras.callbacks.CSVLogger('epoches.csv')\n",
    "    return [vk, ers, chk, rduce_lr]\n",
    "\n",
    "\n",
    "cll = tr()\n",
    "history = model.fit(train_gen,\n",
    "                    validation_data = val_gen,\n",
    "                    batch_size = bs,\n",
    "                    epochs = 50,\n",
    "                    verbose = 1,\n",
    "                    callbacks = cll,\n",
    "                    steps_per_epoch = np.shape(tr_ary)[0] // bs,\n",
    "                    validation_steps = np.shape(vl_ary)[0] // bs\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a41e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = load_model('checkpoint_keypoint_01')\n",
    "\n",
    "n = ts_df['images'].tolist()\n",
    "x = np.zeros((len(n), 384, 384, 1))\n",
    "\n",
    "for i in range(len(n)):\n",
    "    train_img = image.img_to_array(image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + n[\n",
    "        i], color_mode = \"grayscale\", target_size = (384, 512)))\n",
    "    train_img /= 255.0\n",
    "    x[i] = train_img[:, 64:448]\n",
    "\n",
    "pred = classifier.predict(x)\n",
    "\n",
    "summ = 0\n",
    "one_by_one = []\n",
    "for i in range(np.shape(pred)[0]):\n",
    "    y_pred = pred[i]\n",
    "    y_true = ts_ary[i]\n",
    "    x1 = y_pred[42:48].mean()\n",
    "    x2 = y_pred[36:42].mean()\n",
    "    y1 = y_pred[42 + 68:48 + 68].mean()\n",
    "    y2 = y_pred[36 + 68:42 + 68].mean()\n",
    "    summ += np.linalg.norm(y_true - y_pred) / (math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2) * 68)\n",
    "    one_by_one.append(np.linalg.norm(y_true - y_pred) / (math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2) * 68))\n",
    "\n",
    "print(100 * summ / np.shape(pred)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179eface",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "# initializing random values \n",
    "data = np.random.randn(N)\n",
    "\n",
    "# getting data of the histogram \n",
    "count, bins_count = np.histogram(one_by_one, bins = 100)\n",
    "\n",
    "# finding the PDF of the histogram using count values \n",
    "pdf = count / sum(count)\n",
    "\n",
    "# using numpy np.cumsum to calculate the CDF \n",
    "# We can also find using the PDF values by looping and adding \n",
    "cdf = np.cumsum(pdf)\n",
    "\n",
    "to_save = np.zeros((2, len(cdf)))\n",
    "to_save[0] = bins_count[1:]\n",
    "to_save[1] = cdf\n",
    "\n",
    "np.save('C:/Users/DrBah/Desktop/keypoint images/03 - Results/Keypoint detection/05 NME for different pretexts - bar plot/Gender_inpainting_subject.npy', to_save)\n",
    "\n",
    "# plotting PDF and CDF \n",
    "plt.plot(to_save[0], to_save[1], label = \"CDF\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e7a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(super_resolution, high_resolution):\n",
    "    psnr_value = tf.image.psnr(high_resolution, super_resolution, max_val = 255)[0]\n",
    "    return psnr_value\n",
    "\n",
    "\n",
    "def SSIMLoss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "\n",
    "img = np.zeros((1, 384, 384, 1)).astype('double')\n",
    "\n",
    "train_igg = image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + ts_df['images'][\n",
    "    193], color_mode = \"grayscale\", target_size = (384, 512))\n",
    "train_img = image.img_to_array(train_igg)\n",
    "train_img /= 255.0\n",
    "img[0, :, :, :] = train_img[:, 64:448]\n",
    "img = np.array(img)\n",
    "\n",
    "classifier = load_model('checkpoint_keypoint_01')\n",
    "lbl_c = classifier.predict(img)\n",
    "\n",
    "np.save('F:/Poorya/keypoint detection J/final codes/Pretexts/00 NME/Gender_inpainting_subject.npy', lbl_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb069452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poorya-tf24 kernel",
   "language": "python",
   "name": "poorya-tf24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
