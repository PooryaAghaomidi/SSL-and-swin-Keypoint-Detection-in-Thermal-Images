{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed841f58",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09233d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6ee32",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935519f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D, Flatten\n",
    "from tensorflow.keras.layers import AveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from livelossplot.inputs.tf_keras import PlotLossesCallback\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3480c",
   "metadata": {},
   "source": [
    "## lable preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6ffa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tr_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/train_kp.csv')\n",
    "vl_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/val_kp.csv')\n",
    "ts_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/test_kp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_ary(df):\n",
    "    ary = np.zeros((len(df), 136), dtype = int)\n",
    "    for i in range(len(df)):\n",
    "        rep_x = [j for j in range(len(df['x'][i])) if df['x'][i].startswith(',', j)]\n",
    "        rep_y = [j for j in range(len(df['y'][i])) if df['y'][i].startswith(',', j)]\n",
    "        ary[i, 0] = int(df['x'][i][1:rep_x[0]]) / 2\n",
    "        ary[i, 67] = int(df['x'][i][rep_x[-1] + 1:-1]) / 2\n",
    "        ary[i, 68] = (int(df['y'][i][1:rep_y[0]]) - 128) / 2\n",
    "        ary[i, 135] = (int(df['y'][i][rep_y[-1] + 1:-1]) - 128) / 2\n",
    "        for k in range(66):\n",
    "            ary[i, k + 1] = int(df['x'][i][rep_x[k] + 1:rep_x[k + 1]]) / 2\n",
    "            ary[i, k + 69] = (int(df['y'][i][rep_y[k] + 1:rep_y[k + 1]]) - 128) / 2\n",
    "\n",
    "    return ary\n",
    "\n",
    "\n",
    "tr_ary = df_to_ary(tr_df)\n",
    "ts_ary = df_to_ary(ts_df)\n",
    "vl_ary = df_to_ary(vl_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75ece5",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd327ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_partition(x, window_size):\n",
    "    _, height, width, channels = x.shape\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(\n",
    "        x, shape = (-1, patch_num_y, window_size, patch_num_x, window_size, channels)\n",
    "        )\n",
    "    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n",
    "    windows = tf.reshape(x, shape = (-1, window_size, window_size, channels))\n",
    "    return windows\n",
    "\n",
    "\n",
    "def window_reverse(windows, window_size, height, width, channels):\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(\n",
    "        windows,\n",
    "        shape = (-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n",
    "        )\n",
    "    x = tf.transpose(x, perm = (0, 1, 3, 2, 4, 5))\n",
    "    x = tf.reshape(x, shape = (-1, height, width, channels))\n",
    "    return x\n",
    "\n",
    "\n",
    "class DropPath(layers.Layer):\n",
    "    def __init__(self, drop_prob=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def call(self, x):\n",
    "        input_shape = tf.shape(x)\n",
    "        batch_size = input_shape[0]\n",
    "        rank = x.shape.rank\n",
    "        shape = (batch_size,) + (1,) * (rank - 1)\n",
    "        random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape, dtype = x.dtype)\n",
    "        path_mask = tf.floor(random_tensor)\n",
    "        output = tf.math.divide(x, 1 - self.drop_prob) * path_mask\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45198591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowAttention(layers.Layer):\n",
    "    def __init__(\n",
    "        self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs\n",
    "        ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "        self.qkv = layers.Dense(dim * 3, use_bias = qkv_bias)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.proj = layers.Dense(dim)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        num_window_elements = (2 * self.window_size[0] - 1) * (\n",
    "                               2 * self.window_size[1] - 1\n",
    "        )\n",
    "        self.relative_position_bias_table = self.add_weight(\n",
    "            name = 'W',\n",
    "            shape = (num_window_elements, self.num_heads),\n",
    "            initializer = tf.initializers.Zeros(),\n",
    "            trainable = True,\n",
    "            )\n",
    "        coords_h = np.arange(self.window_size[0])\n",
    "        coords_w = np.arange(self.window_size[1])\n",
    "        coords_matrix = np.meshgrid(coords_h, coords_w, indexing = \"ij\")\n",
    "        coords = np.stack(coords_matrix)\n",
    "        coords_flatten = coords.reshape(2, -1)\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = relative_coords.transpose([1, 2, 0])\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)\n",
    "\n",
    "        self.relative_position_index = tf.Variable(\n",
    "            initial_value = tf.convert_to_tensor(relative_position_index), trainable = False\n",
    "            )\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        _, size, channels = x.shape\n",
    "        head_dim = channels // self.num_heads\n",
    "        x_qkv = self.qkv(x)\n",
    "        x_qkv = tf.reshape(x_qkv, shape = (-1, size, 3, self.num_heads, head_dim))\n",
    "        x_qkv = tf.transpose(x_qkv, perm = (2, 0, 3, 1, 4))\n",
    "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
    "        q = q * self.scale\n",
    "        k = tf.transpose(k, perm = (0, 1, 3, 2))\n",
    "        attn = q @ k\n",
    "\n",
    "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
    "        relative_position_index_flat = tf.reshape(\n",
    "            self.relative_position_index, shape = (-1,)\n",
    "            )\n",
    "        relative_position_bias = tf.gather(\n",
    "            self.relative_position_bias_table, relative_position_index_flat\n",
    "            )\n",
    "        relative_position_bias = tf.reshape(\n",
    "            relative_position_bias, shape = (num_window_elements, num_window_elements, -1)\n",
    "            )\n",
    "        relative_position_bias = tf.transpose(relative_position_bias, perm = (2, 0, 1))\n",
    "        attn = attn + tf.expand_dims(relative_position_bias, axis = 0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.get_shape()[0]\n",
    "            mask_float = tf.cast(\n",
    "                tf.expand_dims(tf.expand_dims(mask, axis = 1), axis = 0), tf.float32\n",
    "                )\n",
    "            attn = (\n",
    "                                   tf.reshape(attn, shape = (-1, nW, self.num_heads, size, size))\n",
    "                                   + mask_float\n",
    "            )\n",
    "            attn = tf.reshape(attn, shape = (-1, self.num_heads, size, size))\n",
    "            attn = keras.activations.softmax(attn, axis = -1)\n",
    "        else:\n",
    "            attn = keras.activations.softmax(attn, axis = -1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        x_qkv = attn @ v\n",
    "        x_qkv = tf.transpose(x_qkv, perm = (0, 2, 1, 3))\n",
    "        x_qkv = tf.reshape(x_qkv, shape = (-1, size, channels))\n",
    "        x_qkv = self.proj(x_qkv)\n",
    "        x_qkv = self.dropout(x_qkv)\n",
    "        return x_qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformer(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_patch,\n",
    "        num_heads,\n",
    "        window_size=7,\n",
    "        shift_size=0,\n",
    "        num_mlp=1024,\n",
    "        qkv_bias=True,\n",
    "        dropout_rate=0.0,\n",
    "        **kwargs,\n",
    "        ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.dim = dim  # number of input dimensions\n",
    "        self.num_patch = num_patch  # number of embedded patches\n",
    "        self.num_heads = num_heads  # number of attention heads\n",
    "        self.window_size = window_size  # size of window\n",
    "        self.shift_size = shift_size  # size of window shift\n",
    "        self.num_mlp = num_mlp  # number of MLP nodes\n",
    "\n",
    "        self.norm1 = layers.LayerNormalization(epsilon = 1e-5)\n",
    "        self.attn = WindowAttention(\n",
    "            dim,\n",
    "            window_size = (self.window_size, self.window_size),\n",
    "            num_heads = num_heads,\n",
    "            qkv_bias = qkv_bias,\n",
    "            dropout_rate = dropout_rate,\n",
    "            )\n",
    "        self.drop_path = DropPath(dropout_rate)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon = 1e-5)\n",
    "\n",
    "        self.mlp = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(num_mlp),\n",
    "                layers.Activation(keras.activations.gelu),\n",
    "                layers.Dropout(dropout_rate),\n",
    "                layers.Dense(dim),\n",
    "                layers.Dropout(dropout_rate),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        if min(self.num_patch) < self.window_size:\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.num_patch)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.shift_size == 0:\n",
    "            self.attn_mask = None\n",
    "        else:\n",
    "            height, width = self.num_patch\n",
    "            h_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "                )\n",
    "            w_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "                )\n",
    "            mask_array = np.zeros((1, height, width, 1))\n",
    "            count = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    mask_array[:, h, w, :] = count\n",
    "                    count += 1\n",
    "            mask_array = tf.convert_to_tensor(mask_array)\n",
    "\n",
    "            # mask array to windows\n",
    "            mask_windows = window_partition(mask_array, self.window_size)\n",
    "            mask_windows = tf.reshape(\n",
    "                mask_windows, shape = [-1, self.window_size * self.window_size]\n",
    "                )\n",
    "            attn_mask = tf.expand_dims(mask_windows, axis = 1) - tf.expand_dims(\n",
    "                mask_windows, axis = 2\n",
    "                )\n",
    "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
    "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
    "            self.attn_mask = tf.Variable(initial_value = attn_mask, trainable = False)\n",
    "\n",
    "    def call(self, x):\n",
    "        height, width = self.num_patch\n",
    "        _, num_patches_before, channels = x.shape\n",
    "        x_skip = x\n",
    "        x = self.norm1(x)\n",
    "        x = tf.reshape(x, shape = (-1, height, width, channels))\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = tf.roll(\n",
    "                x, shift = [-self.shift_size, -self.shift_size], axis = [1, 2]\n",
    "                )\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        x_windows = window_partition(shifted_x, self.window_size)\n",
    "        x_windows = tf.reshape(\n",
    "            x_windows, shape = (-1, self.window_size * self.window_size, channels)\n",
    "            )\n",
    "        attn_windows = self.attn(x_windows, mask = self.attn_mask)\n",
    "\n",
    "        attn_windows = tf.reshape(\n",
    "            attn_windows, shape = (-1, self.window_size, self.window_size, channels)\n",
    "            )\n",
    "        shifted_x = window_reverse(\n",
    "            attn_windows, self.window_size, height, width, channels\n",
    "            )\n",
    "        if self.shift_size > 0:\n",
    "            x = tf.roll(\n",
    "                shifted_x, shift = [self.shift_size, self.shift_size], axis = [1, 2]\n",
    "                )\n",
    "        else:\n",
    "            x = shifted_x\n",
    "\n",
    "        x = tf.reshape(x, shape = (-1, height * width, channels))\n",
    "        x = self.drop_path(x)\n",
    "        x = x_skip + x\n",
    "        x_skip = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = self.drop_path(x)\n",
    "        x = x_skip + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3f6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchExtract(layers.Layer):\n",
    "    def __init__(self, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.patch_size_x = patch_size[0]\n",
    "        self.patch_size_y = patch_size[0]\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images = images,\n",
    "            sizes = (1, self.patch_size_x, self.patch_size_y, 1),\n",
    "            strides = (1, self.patch_size_x, self.patch_size_y, 1),\n",
    "            rates = (1, 1, 1, 1),\n",
    "            padding = \"VALID\",\n",
    "            )\n",
    "        patch_dim = patches.shape[-1]\n",
    "        patch_num = patches.shape[1]\n",
    "        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n",
    "\n",
    "\n",
    "class PatchEmbedding(layers.Layer):\n",
    "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_patch = num_patch\n",
    "        self.proj = layers.Dense(embed_dim)\n",
    "        self.pos_embed = layers.Embedding(input_dim = num_patch, output_dim = embed_dim)\n",
    "\n",
    "    def call(self, patch):\n",
    "        pos = tf.range(start = 0, limit = self.num_patch, delta = 1)\n",
    "        return self.proj(patch) + self.pos_embed(pos)\n",
    "\n",
    "\n",
    "class PatchMerging(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_patch, embed_dim):\n",
    "        super().__init__()\n",
    "        self.num_patch = num_patch\n",
    "        self.embed_dim = embed_dim\n",
    "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias = False)\n",
    "\n",
    "    def call(self, x):\n",
    "        height, width = self.num_patch\n",
    "        _, _, C = x.get_shape().as_list()\n",
    "        x = tf.reshape(x, shape = (-1, height, width, C))\n",
    "        x0 = x[:, 0::2, 0::2, :]\n",
    "        x1 = x[:, 1::2, 0::2, :]\n",
    "        x2 = x[:, 0::2, 1::2, :]\n",
    "        x3 = x[:, 1::2, 1::2, :]\n",
    "        x = tf.concat((x0, x1, x2, x3), axis = -1)\n",
    "        x = tf.reshape(x, shape = (-1, (height // 2) * (width // 2), 4 * C))\n",
    "        return self.linear_trans(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd1cad8-ed77-4f26-9445-164cd5fe8f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, ary, batch_size):\n",
    "        self.n = df['images'].tolist()\n",
    "        self.df = df\n",
    "        self.ary = ary\n",
    "        self.batch_size = batch_size\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.n) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        list_IDs_temp = [self.n[k] for k in indexes]\n",
    "        x, y = self.__data_generation(list_IDs_temp, indexes)\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.n))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp, indexes):\n",
    "        images = np.empty((self.batch_size, 384, 384, 1))\n",
    "        kp = np.empty((self.batch_size, 136))\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            train_img = image.img_to_array(image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + ID, color_mode = \"grayscale\", target_size = (\n",
    "            384, 512)))\n",
    "            train_img = train_img[:, 64:448]\n",
    "            train_img /= 255.0\n",
    "            images[i,] = train_img\n",
    "\n",
    "            kp[i,] = self.ary[indexes[i], :]\n",
    "\n",
    "        return images, kp\n",
    "\n",
    "\n",
    "bs = 2\n",
    "train_gen = DataGenerator(tr_df, tr_ary, bs)\n",
    "val_gen = DataGenerator(vl_df, vl_ary, bs)\n",
    "test_gen = DataGenerator(ts_df, ts_ary, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64186d3",
   "metadata": {},
   "source": [
    "## model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01698c1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def PSNR(super_resolution, high_resolution):\n",
    "    psnr_value = tf.image.psnr(high_resolution, super_resolution, max_val = 255)[0]\n",
    "    return psnr_value\n",
    "\n",
    "\n",
    "def SSIMLoss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "\n",
    "def vgg_block(layer_in, n_filters, n_conv):\n",
    "    for _ in range(n_conv):\n",
    "        layer_in = Conv2D(n_filters, (3, 3), padding = 'same', activation = 'relu')(layer_in)\n",
    "    layer_in = BatchNormalization()(layer_in)\n",
    "    layer_in = AveragePooling2D((2, 2), strides = (2, 2))(layer_in)\n",
    "    return layer_in\n",
    "\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    ######################################  INITIALIZATION  ########################################\n",
    "\n",
    "    patch_size = (2, 2)\n",
    "    num_heads = 8\n",
    "    embed_dim = 64\n",
    "    qkv_bias = True\n",
    "    window_size = 2\n",
    "    shift_size = 1\n",
    "    image_dimension = 384\n",
    "    num_mlp = 512\n",
    "    dropout_rate = 0.1\n",
    "\n",
    "    num_patch_x = 384 // patch_size[0]\n",
    "    num_patch_y = 384 // patch_size[1]\n",
    "\n",
    "    weight_decay = 0.0001\n",
    "    label_smoothing = 0.05\n",
    "\n",
    "    drp = 0.0\n",
    "    act = 'relu'\n",
    "\n",
    "    ########################################  BACKBONE  ############################################\n",
    "\n",
    "    img_input = Input(shape = (384, 384, 1))\n",
    "\n",
    "    layer = vgg_block(img_input, 8, 2)\n",
    "    layer = vgg_block(layer, 16, 2)\n",
    "    layer = vgg_block(layer, 32, 2)\n",
    "    layer = vgg_block(layer, 64, 2)\n",
    "    layer = vgg_block(layer, 128, 2)\n",
    "    layer = vgg_block(layer, 256, 2)\n",
    "\n",
    "    x1 = Flatten()(layer)\n",
    "\n",
    "    #########################################  SWIN T  #############################################\n",
    "\n",
    "    x = layers.experimental.preprocessing.RandomCrop(image_dimension, image_dimension)(img_input)\n",
    "    x = layers.experimental.preprocessing.RandomFlip(\"horizontal\")(x)\n",
    "    x = PatchExtract(patch_size)(x)\n",
    "    x = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(x)\n",
    "    x = SwinTransformer(\n",
    "        dim = embed_dim,\n",
    "        num_patch = (num_patch_x, num_patch_y),\n",
    "        num_heads = num_heads,\n",
    "        window_size = window_size,\n",
    "        shift_size = 0,\n",
    "        num_mlp = num_mlp,\n",
    "        qkv_bias = qkv_bias,\n",
    "        dropout_rate = dropout_rate)(x)\n",
    "    x = SwinTransformer(\n",
    "        dim = embed_dim,\n",
    "        num_patch = (num_patch_x, num_patch_y),\n",
    "        num_heads = num_heads,\n",
    "        window_size = window_size,\n",
    "        shift_size = shift_size,\n",
    "        num_mlp = num_mlp,\n",
    "        qkv_bias = qkv_bias,\n",
    "        dropout_rate = dropout_rate)(x)\n",
    "    x = PatchMerging((num_patch_x, num_patch_y), embed_dim = embed_dim)(x)\n",
    "    x2 = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    ########################################  FLATTEN  ############################################\n",
    "\n",
    "    x = layers.Concatenate()([x1, x2])\n",
    "\n",
    "    x = Dense(1024, activation = act)(x)\n",
    "    x = Dropout(drp)(x)\n",
    "    x = Dense(512, activation = act)(x)\n",
    "    x = Dropout(drp)(x)\n",
    "\n",
    "    last = Dense(136)(x)\n",
    "\n",
    "    return Model(inputs = img_input, outputs = last)\n",
    "\n",
    "\n",
    "metrics = [tf.keras.metrics.MeanAbsolutePercentageError()]\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate = 0.001)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "model = get_model()\n",
    "model.compile(loss = loss, optimizer = opt, metrics = metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21459a3f",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b075ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr():\n",
    "    chk = ModelCheckpoint(filepath = 'supervised_checkpoint', monitor = 'val_loss', mode = 'min', verbose = 1, save_best_only = True)\n",
    "    ers = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 0)\n",
    "    rduce_lr = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.5, patience = 5, verbose = 1, mode = \"min\", min_lr = 0.000001)\n",
    "    vk = PlotLossesCallback()\n",
    "    lgg = tf.keras.callbacks.CSVLogger('epoches.csv')\n",
    "    return [vk, lgg, chk, rduce_lr]\n",
    "\n",
    "\n",
    "cll = tr()\n",
    "history = model.fit(train_gen,\n",
    "                    validation_data = val_gen,\n",
    "                    batch_size = bs,\n",
    "                    epochs = 200,\n",
    "                    verbose = 1,\n",
    "                    callbacks = cll,\n",
    "                    steps_per_epoch = np.shape(tr_ary)[0] // bs,\n",
    "                    validation_steps = np.shape(vl_ary)[0] // bs\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bcc323",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((1, 384, 384, 1)).astype('double')\n",
    "myi = 193\n",
    "\n",
    "train_igg = image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + ts_df['images'][\n",
    "    myi], color_mode = \"grayscale\", target_size = (384, 512))\n",
    "train_img = image.img_to_array(train_igg)\n",
    "train_img /= 255.0\n",
    "img[0, :, :, :] = train_img[:, 64:448]\n",
    "img = np.array(img)\n",
    "\n",
    "kp = ts_ary[myi]\n",
    "\n",
    "classifier = load_model('supervised_checkpoint')\n",
    "lbl_c = classifier.predict(img)\n",
    "\n",
    "# summ = 0\n",
    "# for i in range(100):\n",
    "#     start = time()\n",
    "#     lbl_c = classifier.predict(img)\n",
    "#     end   = time()\n",
    "#     summ  = summ + (end - start)\n",
    "\n",
    "x = lbl_c[0, 0:68]\n",
    "y = lbl_c[0, 68:]\n",
    "\n",
    "xx = kp[0:68]\n",
    "yy = kp[68:]\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.imshow(img[0], cmap = 'gray')\n",
    "plt.scatter(y, x)\n",
    "plt.scatter(yy, xx)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7b3823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = ts_df['images'].tolist()\n",
    "x = np.zeros((len(n), 384, 384, 1))\n",
    "\n",
    "for i in range(len(n)):\n",
    "    train_img = image.img_to_array(image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + n[\n",
    "        i], color_mode = \"grayscale\", target_size = (384, 512)))\n",
    "    train_img /= 255.0\n",
    "    x[i] = train_img[:, 64:448]\n",
    "\n",
    "pred = classifier.predict(x)\n",
    "\n",
    "summ = 0\n",
    "one_by_one = []\n",
    "for i in range(np.shape(pred)[0]):\n",
    "    y_pred = pred[i]\n",
    "    y_true = ts_ary[i]\n",
    "    x1 = y_pred[42:48].mean()\n",
    "    x2 = y_pred[36:42].mean()\n",
    "    y1 = y_pred[42 + 68:48 + 68].mean()\n",
    "    y2 = y_pred[36 + 68:42 + 68].mean()\n",
    "    summ += np.linalg.norm(y_true - y_pred) / (math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2) * 68)\n",
    "    one_by_one.append(np.linalg.norm(y_true - y_pred) / (math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2) * 68))\n",
    "\n",
    "print(100 * summ / np.shape(pred)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "# initializing random values \n",
    "data = np.random.randn(N)\n",
    "\n",
    "# getting data of the histogram \n",
    "count, bins_count = np.histogram(one_by_one, bins = 100)\n",
    "\n",
    "# finding the PDF of the histogram using count values \n",
    "pdf = count / sum(count)\n",
    "\n",
    "# using numpy np.cumsum to calculate the CDF \n",
    "# We can also find using the PDF values by looping and adding \n",
    "cdf = np.cumsum(pdf)\n",
    "\n",
    "to_save = np.zeros((2, len(cdf)))\n",
    "to_save[0] = bins_count[1:]\n",
    "to_save[1] = cdf\n",
    "\n",
    "#np.save('C:/Users/DrBah/Desktop/keypoint images/03 - Results/Keypoint detection/05 NME for different pretexts - bar plot/Gender_inpainting_subject_rotation.npy', to_save)\n",
    "\n",
    "# plotting PDF and CDF \n",
    "plt.plot(to_save[0], to_save[1], label = \"CDF\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poorya-tf24 kernel",
   "language": "python",
   "name": "poorya-tf24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
