{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed841f58",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09233d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6ee32",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935519f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, Convolution2D, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from livelossplot.inputs.tf_keras import PlotLossesCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3480c",
   "metadata": {},
   "source": [
    "## lable preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6ffa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tr_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/train_faces.csv')\n",
    "ts_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/test_faces.csv')\n",
    "vl_df = pd.read_csv('F:/poorya/datasets/ThermalFaceDatabase/val_faces.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75ece5",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d7e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_acc(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.round(y_true), K.round(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d5baa-a804-4ade-8bf7-a2377c1bb3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, batch_size):\n",
    "        self.n = df['name'].tolist()\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.n) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        list_IDs_temp = [self.n[k] for k in indexes]\n",
    "        x, y = self.__data_generation(list_IDs_temp, indexes)\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.n))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp, indexes):\n",
    "        images = np.empty((self.batch_size, 384, 384, 1))\n",
    "        face = np.empty((self.batch_size, 4))\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            train_img = image.img_to_array(image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + ID, color_mode = \"grayscale\", target_size = (\n",
    "            384, 512)))\n",
    "            train_img = train_img[:, 64:448]\n",
    "            train_img /= 255.0\n",
    "            images[i,] = train_img\n",
    "\n",
    "            face[i, 0] = int(self.df.iloc[indexes[i]]['Xmax']) // 2\n",
    "            face[i, 1] = int(self.df.iloc[indexes[i]]['Xmin']) // 2\n",
    "            face[i, 2] = int(self.df.iloc[indexes[i]]['Ymin']) // 2\n",
    "            face[i, 3] = int(self.df.iloc[indexes[i]]['Ymax']) // 2\n",
    "\n",
    "        return images, face\n",
    "\n",
    "\n",
    "bs = 8\n",
    "train_gen = DataGenerator(tr_df, bs)\n",
    "val_gen = DataGenerator(vl_df, bs)\n",
    "test_gen = DataGenerator(ts_df, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64186d3",
   "metadata": {},
   "source": [
    "## model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01698c1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def PSNR(super_resolution, high_resolution):\n",
    "    psnr_value = tf.image.psnr(high_resolution, super_resolution, max_val = 1)[0]\n",
    "    return psnr_value\n",
    "\n",
    "\n",
    "def SSIMLoss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    ######################################  INITIALIZATION  ########################################\n",
    "\n",
    "    metrics = [tf.keras.metrics.MeanAbsolutePercentageError()]\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 0.05)\n",
    "    loss = tf.keras.losses.MeanSquaredError()\n",
    "    drp = 0.0\n",
    "    act = 'relu'\n",
    "\n",
    "    ########################################  BACKBONE  ############################################\n",
    "    img_input = Input(shape = (384, 384, 1))\n",
    "\n",
    "    full_model = load_model('checkpoint_loss2', custom_objects = {'PSNR': PSNR, 'SSIMLoss': SSIMLoss})\n",
    "    model = Model(inputs = full_model.inputs, outputs = full_model.layers[24].output)\n",
    "    model.trainable = False\n",
    "    model.summary()\n",
    "\n",
    "    x = model(img_input)\n",
    "    ########################################  FLATTEN  #############################################\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(128, kernel_initializer = 'normal', activation = act)(x)\n",
    "    x = Dropout(drp)(x)\n",
    "\n",
    "    last = Dense(4)(x)\n",
    "\n",
    "    modell = Model(inputs = img_input, outputs = last)\n",
    "    modell.compile(loss = loss, optimizer = opt, metrics = metrics)\n",
    "\n",
    "    return modell\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21459a3f",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b075ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr():\n",
    "    chk = ModelCheckpoint(filepath = 'checkpoint_face', monitor = 'val_loss', mode = 'min', verbose = 1, save_best_only = True)\n",
    "    ers = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 75)\n",
    "    rduce_lr = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.5, patience = 5, verbose = 1, mode = \"min\", min_lr = 0.000001)\n",
    "    vk = PlotLossesCallback()\n",
    "    return [chk, vk, rduce_lr]\n",
    "\n",
    "\n",
    "cll = tr()\n",
    "history = model.fit(train_gen,\n",
    "                    validation_data = val_gen,\n",
    "                    batch_size = bs,\n",
    "                    epochs = 100,\n",
    "                    verbose = 1,\n",
    "                    callbacks = cll,\n",
    "                    steps_per_epoch = len(tr_df) // bs,\n",
    "                    validation_steps = len(vl_df) // bs\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bcc323",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3dab6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "img = np.zeros((1, 384, 384, 1)).astype('double')\n",
    "n = ts_df['name'].tolist()\n",
    "i = 2\n",
    "\n",
    "train_igg = image.load_img('F:/poorya/datasets/ThermalFaceDatabase/' + n[i], color_mode = \"grayscale\", target_size = (\n",
    "384, 512))\n",
    "train_img = image.img_to_array(train_igg)\n",
    "train_img = train_img[:, 64:448]\n",
    "train_img /= 255.0\n",
    "img[0, :, :, :] = train_img\n",
    "img = np.array(img)\n",
    "\n",
    "classifier = load_model('checkpoint_face')\n",
    "\n",
    "summ = 0\n",
    "for i in range(100):\n",
    "    start = time()\n",
    "    lbl_c = classifier.predict(img)\n",
    "    end = time()\n",
    "    summ = summ + (end - start)\n",
    "\n",
    "a = np.ones(np.shape(train_igg)[0])\n",
    "b = np.ones(np.shape(train_igg)[1])\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.imshow(train_igg)\n",
    "\n",
    "plt.plot(lbl_c[0][2] * b)\n",
    "plt.plot(lbl_c[0][3] * b)\n",
    "plt.plot((lbl_c[0][1] + 64) * a, range(np.shape(train_igg)[0]))\n",
    "plt.plot((lbl_c[0][0] + 64) * a, range(np.shape(train_igg)[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf3e325-237a-4017-b91e-8ada389f64a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92049a22",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2108d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_loss, tst_acc = classifier.evaluate(test_gen, steps = len(ts_df) // bs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poorya kernel",
   "language": "python",
   "name": "poorya"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
